###############################
####KICKSTARTER EXPLORATION####
###############################

#IMPORT DATASET
df<-read.csv('https://raw.githubusercontent.com/CallBark/kickstarter/main/Kickstarter_NA.csv', header = T)
Testing<-read.csv('https://raw.githubusercontent.com/Dereklip/GSBA576/main/Testing_v2.csv', header = T)
Training<-read.csv('https://raw.githubusercontent.com/Dereklip/GSBA576/main/Training_v2.csv', header = T)
Validation<-read.csv('https://raw.githubusercontent.com/Dereklip/GSBA576/main/Validation_v2.csv', header = T)

##DESCRIPTIVE SUMMARY STATISTICS##
View(df)
dim(df)
summary(df) #generates the "six number summary" statistics for each variable
dim(Testing)
dim(Training)
dim(Validation)

##DATA VISUALIZATIONS
hist(df$USD.Pledged, prob = TRUE) #generates a histogram for the USD.Pledged variable
curve(dnorm(x, mean = mean(df$USD.Pledged), sd = sd(df$USD.Pledged)), col = "darkblue", lwd = 2, add = TRUE) #add calibrated normal density curve to histogram
plot(density(df$USD.Pledged)) #generates a nonparametric density estimate of the distribution of the usd_pledged variable
hist(df$Goal, prob = TRUE) #generates a histogram for the Goal variable
curve(dnorm(x, mean = mean(df$Goal), sd = sd(df$Goal)), col = "darkblue", lwd = 2, add = TRUE) #add calibrated normal density curve to histogram
pairs(df[,3:8]) #generate pairs of scatter plots from the variables in columns 3-8

##BUILDING A LINEAR MODEL TO QUANTIFY THE RELATIONSHIP BETWEEN USD PLEDGED AND NUMBER OF BACKERS##
M1<-lm(USD.Pledged~Backers.Count, df)  #model: USD Pledged = B_0+B_1(backers_count)+e
summary(M1) #produces the summary output of the model
confint(M1) #returns upper and lower bounds from the 95% confidence interval for each model parameter

##VISUALIZATIONS
plot(df$USD.Pledged~df$Backers.Count) #scatter plot of USD Pledged vs. Backers.Count again
abline(M1$coefficients[1], M1$coefficients[2], col='blue', lwd=2) #add regression line to plot

##PLOTTING FITTED (PREDICTED) VALUES
plot(M1$fitted.values~df$Backers.Count)
abline(M1$coefficients[1], M1$coefficients[2], col='blue', lwd=2) #add regression line to plot

##RESIDUAL ANALYSIS##
plot(M1$residuals)
abline(0,0,col='black')
hist(M1$residuals)
summary(M1$residuals)
curve(dnorm(x, mean = mean(M1$residuals), sd = sd(M1$residuals)), col = "darkblue", lwd = 2, add = TRUE) #add calibrated normal density curve to histogram

##QUESTION: HOW MUCH CAN WE EXPECT THE USD PLEDGE TO BE CONSIDERING THE VARIABLES?##
##EXPLORING UNIVARIATE REGRESSION MODELS##
M2<-lm(USD.Pledged~Blurb.Length, df)  #builds the model: USD.Pledged = B_0+B_1(Blurb.length)+e
summary(M2)  #returns summary output from the model M2

M3<-lm(USD.Pledged~Blurb.Caps, df)  #builds the model: USD.Pledged = B_0+B_1(Blurb.caps)+e
summary(M3)  #returns summary output from the model M3

M4<-lm(USD.Pledged~Name.Length, df)  #builds the model: USD.Pledged = B_0+B_1(Name.Length)+e
summary(M4)  #returns summary output from the model M4

M5<-lm(USD.Pledged~Spotlight, df)  #builds the model: USD.Pledged = B_0+B_1(spotlight)+e
summary(M5)  #returns summary output from the model M5

M6<-lm(USD.Pledged~Staff.Pick, df)  #builds the model: USD.Pledged = B_0+B_1(staff_pick)+e
summary(M6)  #returns summary output from the model M6

M7<-lm(USD.Pledged~Goal, df)  #builds the model: USD.Pledged = B_0+B_1(goal)+e
summary(M7)  #returns summary output from the model M7

##EXPLORING MULTIVARIATE REGRESSION MODELS##
#QUESTION: WILL CONTROLLING FOR SPOTLIGHT AND STAFF PICK INFLUENCE THE AMOUNT OF USD PLEDGED?
##BUILD A MULTIVARIATE MODEL TO PREDICT USD PLEDGED CONTROLLING FOR BOTH SPOTLIGHT AND STAFF PICK##
M8<-lm(USD.Pledged~Blurb.Length+Blurb.Caps+Name.Length+Backers.Count+Spotlight+Staff.Pick+Goal, df) #model: USD.Pledged = B_0+B_1(Backers.Count)+B_2(Spotlight)+B_2(staff_pick)+e
summary(M8)
cbind( M8$coefficients, confint(M8))

##RESIDUAL ANALYSIS##
plot(M8$residuals) #plots residuals
abline(0,0,col='black', lwd = 4)
hist(M8$residuals, prob = TRUE)
curve(dnorm(x, mean = mean(M8$residuals), sd = sd(M8$residuals)), col = "darkblue", lwd = 2, add=TRUE)
summary(M8$residuals)


#BUILD MODEL M8 WITH ONLY THE TRAINING DATA PARTITION
M9<-lm(USD.Pledged~Blurb.Length+Blurb.Caps+Name.Length+Backers.Count+Spotlight+Staff.Pick+Goal, Training) #model: USD.Pledged = B_0+B_1(Backers.Count)+B_2(Spotlight)+B_2(staff_pick)+e
summary(M9)


#RIDGE REGRESSION / no penalty to the coefficients
library(MASS)
names(Training)[1] <- "y"
lm.ridge(y ~ ., Training)
plot(lm.ridge(y ~ ., Training,
              lambda = seq(0,0.1,0.001)))
select(lm.ridge(y ~ ., Training,
                lambda = seq(0,0.1,0.0001)))



##CALCULATE ROOT MEAN SQUARE PREDICTION ERROR ON TEST DATA: THE IN-SAMPLE ERROR MEASURE
install.packages('caret') #installs the caret package
library(caret)  #calls the caret library to use createDataPartition()
RMSE_IN<-sqrt(sum((M9$fitted.values-Testing$USD.Pledged)^2)/length(Testing$USD.Pledged))
RMSE_IN #report root mean squared error (E_out) using the out-of-sample testing data

#EVALUATE M9 ON THE TEST PARTITION TO COMPUTE THE OUT-OF-SAMPLE PREDICTIONS
predictions<-predict(M9, Testing)
View(predictions) # view predictions for December

##CALCULATE ROOT MEAN SQUARE PREDICTION ERROR ON TEST DATA: THE OUT-OF-SAMPLE ERROR MEASURE
RMSE_OUT<-sqrt(sum((predictions-Testing$USD.Pledged)^2)/length(Testing$USD.Pledged))
RMSE_OUT #report root mean squared error (E_out) using the out-of-sample testing data
